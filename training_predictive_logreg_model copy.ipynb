{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCOPE:\n",
    "* Create Target (1,0 classes) based on whether farmer paid at maturity or not\n",
    "Split dataset from Inception till half of 2022\n",
    "Predict probability using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score,f1_score,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier,BaggingClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install --index-url=https://pypi.org/simple/ --trusted-host=pypi.org catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = r'C:\\Users\\JenniferEbereChinabu\\OneDrive - AFEX Commodities Exchange Limited\\Documents\\AFEX ML Credit Score\\credit_score\\inception_till_2022midpoint_dataset.csv'\n",
    "training_dataset = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r'C:\\Users\\JenniferEbereChinabu\\OneDrive - AFEX Commodities Exchange Limited\\Documents\\AFEX ML Credit Score\\credit_score\\post_2022_dataset.csv'\n",
    "test_dataset = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3352\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046827 -> initscore=-3.013335\n",
      "[LightGBM] [Info] Start training from score -3.013335\n",
      "==================== Model: Without Polynomial Features (Training Data) ====================\n",
      "Accuracy: 0.9991889699918897\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      0.99      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       0.99      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.991206313416009\n",
      "\n",
      "==================== Model: Without Polynomial Features (Test Data) ====================\n",
      "Accuracy: 0.995088957506249\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.80      0.50      0.62       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       0.90      0.75      0.81     34005\n",
      "weighted avg       0.99      1.00      0.99     34005\n",
      "\n",
      "F1 Score (Test Data): 0.6160919540229886\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.090100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 87878\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046827 -> initscore=-3.013335\n",
      "[LightGBM] [Info] Start training from score -3.013335\n",
      "==================== Model: With Polynomial Features (Training Data) ====================\n",
      "Accuracy: 0.9995840871753281\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      1.00      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       1.00      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9954853273137697\n",
      "\n",
      "==================== Model: With Polynomial Features (Test Data) ====================\n",
      "Accuracy: 0.9967651815909425\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.98      0.60      0.75       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       0.99      0.80      0.87     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.7453703703703703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a dataset named 'training_dataset'\n",
    "# Replace 'target_variable' with the actual target variable in your dataset\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "model_no_poly = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler(), LGBMClassifier(random_state=42))\n",
    "model_with_poly = make_pipeline(SimpleImputer(strategy='mean'), PolynomialFeatures(degree=2), StandardScaler(), LGBMClassifier(random_state=42))\n",
    "\n",
    "# Train and evaluate models without and with polynomial features\n",
    "models = {'Without Polynomial Features': model_no_poly, 'With Polynomial Features': model_with_poly}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the training data\n",
    "    y_pred_train = model.predict(X_test)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred_test = model.predict(test_x)\n",
    "\n",
    "    # Model evaluation for training dataset\n",
    "    print(\"=\"*20, f\"Model: {model_name} (Training Data)\", \"=\"*20)\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "    print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "    print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "    # Model evaluation for test dataset\n",
    "    print(\"=\"*20, f\"Model: {model_name} (Test Data)\", \"=\"*20)\n",
    "    print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "    print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "    print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3135\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 40\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046827 -> initscore=-3.013335\n",
      "[LightGBM] [Info] Start training from score -3.013335\n",
      "==================== LightGBM ====================\n",
      "Training Data:\n",
      "Accuracy: 0.9993345394805249\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       0.99      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9927992799279928\n",
      "\n",
      "Test Data:\n",
      "Accuracy: 0.9946772533450963\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.72      0.53      0.61       268\n",
      "\n",
      "    accuracy                           0.99     34005\n",
      "   macro avg       0.86      0.76      0.80     34005\n",
      "weighted avg       0.99      0.99      0.99     34005\n",
      "\n",
      "F1 Score (Test Data): 0.610752688172043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define numerical features and target variable\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# LightGBM model\n",
    "lgb_model = LGBMClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_train_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test_lgb = lgb_model.predict(test_x)\n",
    "\n",
    "# Model evaluation for training dataset\n",
    "print(\"=\"*20, \"LightGBM\", \"=\"*20)\n",
    "print(\"Training Data:\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_train_lgb)}')\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred_train_lgb))\n",
    "print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train_lgb)}\\n')\n",
    "\n",
    "# Model evaluation for test dataset\n",
    "print(\"Test Data:\")\n",
    "print(f'Accuracy: {accuracy_score(test_y, y_pred_test_lgb)}')\n",
    "print('Classification Report:\\n', classification_report(test_y, y_pred_test_lgb))\n",
    "print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test_lgb)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== RandomForest ====================\n",
      "Training Data:\n",
      "Accuracy: 0.9994385176866929\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      0.99      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       1.00      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9938955460094957\n",
      "\n",
      "Test Data:\n",
      "Accuracy: 0.9960005881488017\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       1.00      0.49      0.66       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       1.00      0.75      0.83     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.66\n",
      "\n",
      "==================== GradientBoosting ====================\n",
      "Training Data:\n",
      "Accuracy: 0.9994177220454593\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       1.00      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9936794582392777\n",
      "\n",
      "Test Data:\n",
      "Accuracy: 0.9965299220702838\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.97      0.57      0.72       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       0.99      0.79      0.86     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.7230046948356809\n",
      "\n",
      "==================== AdaBoost ====================\n",
      "Training Data:\n",
      "Accuracy: 0.997774866388005\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      0.96      0.98      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       0.99      0.98      0.99     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9754079521948976\n",
      "\n",
      "Test Data:\n",
      "Accuracy: 0.9922658432583443\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     33737\n",
      "           1       1.00      0.02      0.04       268\n",
      "\n",
      "    accuracy                           0.99     34005\n",
      "   macro avg       1.00      0.51      0.52     34005\n",
      "weighted avg       0.99      0.99      0.99     34005\n",
      "\n",
      "F1 Score (Test Data): 0.03663003663003663\n",
      "\n",
      "==================== Bagging ====================\n",
      "Training Data:\n",
      "Accuracy: 0.9994593133279265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       1.00      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9941282746160794\n",
      "\n",
      "Test Data:\n",
      "Accuracy: 0.9970298485516835\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.95      0.66      0.78       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       0.97      0.83      0.89     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.7770419426048565\n",
      "\n",
      "==================== CatBoost ====================\n",
      "Training Data:\n",
      "Accuracy: 0.9992721525568241\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       0.99      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9921188921414096\n",
      "\n",
      "Test Data:\n",
      "Accuracy: 0.9955888839876489\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.92      0.48      0.63       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       0.96      0.74      0.82     34005\n",
      "weighted avg       1.00      1.00      0.99     34005\n",
      "\n",
      "F1 Score (Test Data): 0.6323529411764706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define numerical features and target variable\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Bagging': BaggingClassifier(random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(random_state=42, verbose=0)  # CatBoost is categorical-feature-friendly\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the training data\n",
    "    y_pred_train = model.predict(X_test)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred_test = model.predict(test_x)\n",
    "\n",
    "    # Model evaluation for training dataset\n",
    "    print(f\"{'='*20} {model_name} {'='*20}\")\n",
    "    print(\"Training Data:\")\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "    print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "    print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "    # Model evaluation for test dataset\n",
    "    print(\"Test Data:\")\n",
    "    print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "    print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "    print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical features and target variable\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Assuming 'X_train' and 'X_test' are your feature matrices\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "test_x_poly = poly.transform(test_x)\n",
    "\n",
    "# List of classifiers\n",
    "classifiers = [\n",
    "    ('RandomForest', RandomForestClassifier(random_state=42)),\n",
    "    ('GradientBoosting', GradientBoostingClassifier(random_state=42)),\n",
    "    ('AdaBoost', AdaBoostClassifier(random_state=42)),\n",
    "    ('Bagging', BaggingClassifier(base_estimator=LGBMClassifier(random_state=42), random_state=42))\n",
    "]\n",
    "\n",
    "# Iterate through classifiers\n",
    "for clf_name, clf in classifiers:\n",
    "    # Train the model with polynomial features\n",
    "    clf.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Make predictions on the training data\n",
    "    y_pred_train = clf.predict(X_test_poly)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred_test = clf.predict(test_x_poly)\n",
    "\n",
    "    # Model evaluation for training dataset\n",
    "    print(\"=\"*20, f\"{clf_name} with Polynomial Features\", \"=\"*20)\n",
    "    print(\"Training Data:\")\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "    print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "    print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "    # Model evaluation for test dataset\n",
    "    print(\"Test Data:\")\n",
    "    print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "    print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "    print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== RandomForestClassifier (Training Data) ====================\n",
      "Accuracy: 0.9995840871753281\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      1.00      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       1.00      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9954853273137697\n",
      "\n",
      "==================== RandomForestClassifier (Test Data) ====================\n",
      "Accuracy: 0.9965299220702838\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       1.00      0.56      0.72       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       1.00      0.78      0.86     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.7177033492822966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define numerical features and target variable\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Assuming 'X_train' and 'X_test' are your feature matrices\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "test_x_poly = poly.transform(test_x)\n",
    "\n",
    "# Define model\n",
    "model_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_rf.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_train = model_rf.predict(X_test_poly)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = model_rf.predict(test_x_poly)\n",
    "\n",
    "# Model evaluation for training dataset\n",
    "print(\"=\"*20, \"RandomForestClassifier (Training Data)\", \"=\"*20)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "# Model evaluation for test dataset\n",
    "print(\"=\"*20, \"RandomForestClassifier (Test Data)\", \"=\"*20)\n",
    "print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical features and target variable\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Assuming 'X_train' and 'X_test' are your feature matrices\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "test_x_poly = poly.transform(test_x)\n",
    "\n",
    "# Define model\n",
    "model_gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_gbc.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_train = model_gbc.predict(X_test_poly)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = model_gbc.predict(test_x_poly)\n",
    "\n",
    "# Model evaluation for training dataset\n",
    "print(\"=\"*20, \"GradientBoostingClassifier (Training Data)\", \"=\"*20)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "# Model evaluation for test dataset\n",
    "print(\"=\"*20, \"GradientBoostingClassifier (Test Data)\", \"=\"*20)\n",
    "print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== AdaBoostClassifier (Training Data) ====================\n",
      "Accuracy: 0.9981491879302098\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.98      0.98      0.98      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       0.99      0.99      0.99     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9798140167838512\n",
      "\n",
      "==================== AdaBoostClassifier (Test Data) ====================\n",
      "Accuracy: 0.993353918541391\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     33737\n",
      "           1       0.85      0.19      0.31       268\n",
      "\n",
      "    accuracy                           0.99     34005\n",
      "   macro avg       0.92      0.60      0.65     34005\n",
      "weighted avg       0.99      0.99      0.99     34005\n",
      "\n",
      "F1 Score (Test Data): 0.31097560975609756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define numerical features and target variable\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Assuming 'X_train' and 'X_test' are your feature matrices\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "test_x_poly = poly.transform(test_x)\n",
    "\n",
    "# Define model\n",
    "model_abc = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_abc.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_train = model_abc.predict(X_test_poly)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = model_abc.predict(test_x_poly)\n",
    "\n",
    "# Model evaluation for training dataset\n",
    "print(\"=\"*20, \"AdaBoostClassifier (Training Data)\", \"=\"*20)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "# Model evaluation for test dataset\n",
    "print(\"=\"*20, \"AdaBoostClassifier (Test Data)\", \"=\"*20)\n",
    "print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== BaggingClassifier (Training Data) ====================\n",
      "Accuracy: 0.9994385176866929\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       1.00      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9938983050847457\n",
      "\n",
      "==================== BaggingClassifier (Test Data) ====================\n",
      "Accuracy: 0.9967357741508601\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.96      0.61      0.75       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       0.98      0.80      0.87     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.7459954233409613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define numerical features and target variable\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Assuming 'X_train' and 'X_test' are your feature matrices\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "test_x_poly = poly.transform(test_x)\n",
    "\n",
    "# Define model\n",
    "model_bc = BaggingClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_bc.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_train = model_bc.predict(X_test_poly)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = model_bc.predict(test_x_poly)\n",
    "\n",
    "# Model evaluation for training dataset\n",
    "print(\"=\"*20, \"BaggingClassifier (Training Data)\", \"=\"*20)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "# Model evaluation for test dataset\n",
    "print(\"=\"*20, \"BaggingClassifier (Test Data)\", \"=\"*20)\n",
    "print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenniferEbereChinabu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.462434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84526\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047305 -> initscore=-3.002670\n",
      "[LightGBM] [Info] Start training from score -3.002670\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.501788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84526\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047597 -> initscore=-2.996229\n",
      "[LightGBM] [Info] Start training from score -2.996229\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.473877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84526\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.045954 -> initscore=-3.033079\n",
      "[LightGBM] [Info] Start training from score -3.033079\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.431774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84526\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046297 -> initscore=-3.025280\n",
      "[LightGBM] [Info] Start training from score -3.025280\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.440384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84526\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046203 -> initscore=-3.027402\n",
      "[LightGBM] [Info] Start training from score -3.027402\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.430748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84526\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048475 -> initscore=-2.977015\n",
      "[LightGBM] [Info] Start training from score -2.977015\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.443404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84526\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.047108 -> initscore=-3.007063\n",
      "[LightGBM] [Info] Start training from score -3.007063\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.496283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84526\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046489 -> initscore=-3.020932\n",
      "[LightGBM] [Info] Start training from score -3.020932\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.491472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84526\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046515 -> initscore=-3.020346\n",
      "[LightGBM] [Info] Start training from score -3.020346\n",
      "[LightGBM] [Info] Number of positive: 9007, number of negative: 183339\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.483369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 84526\n",
      "[LightGBM] [Info] Number of data points in the train set: 192346, number of used features: 791\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046640 -> initscore=-3.017536\n",
      "[LightGBM] [Info] Start training from score -3.017536\n",
      "==================== BaggingClassifier (Training Data) ====================\n",
      "Accuracy: 0.9995009046103936\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       1.00      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9945774966109355\n",
      "\n",
      "==================== BaggingClassifier (Test Data) ====================\n",
      "Accuracy: 0.9965887369504485\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.99      0.57      0.73       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       1.00      0.79      0.86     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.7251184834123223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define numerical features and target variable\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Assuming 'X_train' and 'X_test' are your feature matrices\n",
    "# Create polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "test_x_poly = poly.transform(test_x)\n",
    "\n",
    "# Define model\n",
    "model_blgb = BaggingClassifier(base_estimator=LGBMClassifier(random_state=42), random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_blgb.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions on the training data\n",
    "y_pred_train = model_blgb.predict(X_test_poly)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_test = model_blgb.predict(test_x_poly)\n",
    "\n",
    "# Model evaluation for training dataset\n",
    "print(\"=\"*20, \"BaggingClassifier (Training Data)\", \"=\"*20)\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "# Model evaluation for test dataset\n",
    "print(\"=\"*20, \"BaggingClassifier (Test Data)\", \"=\"*20)\n",
    "print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Model: Without Polynomial Features (Training Data) ====================\n",
      "Accuracy: 0.9994593133279265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       1.00      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9941282746160794\n",
      "\n",
      "==================== Model: Without Polynomial Features (Test Data) ====================\n",
      "Accuracy: 0.9971180708719306\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.97      0.66      0.78       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       0.98      0.83      0.89     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.7822222222222223\n",
      "\n",
      "==================== Model: With Polynomial Features (Training Data) ====================\n",
      "Accuracy: 0.9994593133279265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       1.00      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9941256213285135\n",
      "\n",
      "==================== Model: With Polynomial Features (Test Data) ====================\n",
      "Accuracy: 0.9973239229525069\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.92      0.73      0.81       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       0.96      0.86      0.90     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.8108108108108107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a dataset named 'training_dataset'\n",
    "# Replace 'target_variable' with the actual target variable in your dataset\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "model_no_poly = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler(), BaggingClassifier(random_state=42))\n",
    "model_with_poly = make_pipeline(SimpleImputer(strategy='mean'), PolynomialFeatures(degree=2), StandardScaler(), BaggingClassifier(random_state=42))\n",
    "\n",
    "# Train and evaluate models without and with polynomial features\n",
    "models = {'Without Polynomial Features': model_no_poly, 'With Polynomial Features': model_with_poly}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the training data\n",
    "    y_pred_train = model.predict(X_test)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred_test = model.predict(test_x)\n",
    "\n",
    "    # Model evaluation for training dataset\n",
    "    print(\"=\"*20, f\"Model: {model_name} (Training Data)\", \"=\"*20)\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "    print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "    print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "    # Model evaluation for test dataset\n",
    "    print(\"=\"*20, f\"Model: {model_name} (Test Data)\", \"=\"*20)\n",
    "    print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "    print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "    print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Model: Without Polynomial Features (Training Data) ====================\n",
      "Accuracy: 0.9926175473620729\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     45877\n",
      "           1       0.95      0.88      0.92      2210\n",
      "\n",
      "    accuracy                           0.99     48087\n",
      "   macro avg       0.97      0.94      0.96     48087\n",
      "weighted avg       0.99      0.99      0.99     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9166079398637538\n",
      "\n",
      "==================== Model: Without Polynomial Features (Test Data) ====================\n",
      "Accuracy: 0.998794294956624\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       1.00      0.85      0.92       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       1.00      0.92      0.96     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.9171717171717172\n",
      "\n",
      "==================== Model: With Polynomial Features (Training Data) ====================\n",
      "Accuracy: 0.9926591386445401\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     45877\n",
      "           1       0.96      0.88      0.92      2210\n",
      "\n",
      "    accuracy                           0.99     48087\n",
      "   macro avg       0.98      0.94      0.96     48087\n",
      "weighted avg       0.99      0.99      0.99     48087\n",
      "\n",
      "F1 Score (Training Data): 0.916607606898181\n",
      "\n",
      "==================== Model: With Polynomial Features (Test Data) ====================\n",
      "Accuracy: 0.9977356271136597\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.99      0.72      0.83       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       0.99      0.86      0.92     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.8336933045356373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a dataset named 'training_dataset'\n",
    "# Replace 'target_variable' with the actual target variable in your dataset\n",
    "numerical_features = ['farm_size', 'bags', 'gross_weight', 'net_weight', 'moisture', 'total_commodity_price', 'price_per_tonne', 'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg',\n",
    "'interest', 'admin_fee', 'equity', 'to_balance', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans', 'avg_loan_repayment_rate', 'time_since_last_loan', 'time_since_last_loan_month', 'percentage_unrepaid_loans']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "model_no_poly = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler(), BaggingClassifier(random_state=42))\n",
    "model_with_poly = make_pipeline(SimpleImputer(strategy='mean'), PolynomialFeatures(degree=2), StandardScaler(), BaggingClassifier(random_state=42))\n",
    "\n",
    "# Train and evaluate models without and with polynomial features\n",
    "models = {'Without Polynomial Features': model_no_poly, 'With Polynomial Features': model_with_poly}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the training data\n",
    "    y_pred_train = model.predict(X_test)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred_test = model.predict(test_x)\n",
    "\n",
    "    # Model evaluation for training dataset\n",
    "    print(\"=\"*20, f\"Model: {model_name} (Training Data)\", \"=\"*20)\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "    print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "    print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "    # Model evaluation for test dataset\n",
    "    print(\"=\"*20, f\"Model: {model_name} (Test Data)\", \"=\"*20)\n",
    "    print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "    print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "    print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have datasets named 'training_dataset' and 'test_dataset'\n",
    "# Replace 'target_variable' with the actual target variable in your dataset\n",
    "numerical_features = ['farm_size', 'bags', 'gross_weight', 'net_weight', 'moisture', 'total_commodity_price', 'price_per_tonne', 'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg',\n",
    "                      'interest', 'admin_fee', 'equity', 'to_balance', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans', 'avg_loan_repayment_rate', 'time_since_last_loan', 'time_since_last_loan_month', 'percentage_unrepaid_loans']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "model_no_poly = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler(), BaggingClassifier(random_state=42))\n",
    "model_with_poly = make_pipeline(SimpleImputer(strategy='mean'), PolynomialFeatures(degree=2), StandardScaler(), BaggingClassifier(random_state=42))\n",
    "\n",
    "# Train and evaluate models without and with polynomial features\n",
    "models = {'Without Polynomial Features': model_no_poly, 'With Polynomial Features': model_with_poly}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the training data\n",
    "    y_pred_train = model.predict(X_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred_test = model.predict(test_x)\n",
    "\n",
    "    # Model evaluation for training dataset\n",
    "    print(\"=\"*20, f\"Model: {model_name} (Training Data)\", \"=\"*20)\n",
    "    print(f'Accuracy: {accuracy_score(y_train, y_pred_train)}')\n",
    "    print('Classification Report:\\n', classification_report(y_train, y_pred_train))\n",
    "    print(f'F1 Score (Training Data): {f1_score(y_train, y_pred_train)}\\n')\n",
    "\n",
    "    # Model evaluation for test dataset\n",
    "    print(\"=\"*20, f\"Model: {model_name} (Test Data)\", \"=\"*20)\n",
    "    print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "    print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "    print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')\n",
    "\n",
    "    # Merge binary predictions back into the test dataset\n",
    "    test_dataset[f'{model_name}_prediction'] = y_pred_test\n",
    "\n",
    "    # Get predicted probabilities for the test dataset\n",
    "    y_prob_test = model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "    # Transform the probabilities to a scale between 100 and 800\n",
    "    min_score = 100\n",
    "    max_score = 800\n",
    "\n",
    "    # Scale the probabilities to the desired range\n",
    "    scaled_scores = min_score + (max_score - min_score) * y_prob_test\n",
    "\n",
    "    # Add the scores to the test dataset\n",
    "    test_dataset[f'{model_name}_score'] = scaled_scores\n",
    "\n",
    "# Display the resulting test dataset with predictions and scores\n",
    "print(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenniferEbereChinabu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\JenniferEbereChinabu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:458: UserWarning: X has feature names, but SimpleImputer was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils import resample\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'X' is your feature matrix and 'y' is your target variable\n",
    "# Replace 'X' and 'y' with your actual variable names\n",
    "\n",
    "numerical_features = ['farm_size', 'bags', 'gross_weight', 'net_weight', 'moisture', 'total_commodity_price', 'price_per_tonne', 'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg',\n",
    "'interest', 'admin_fee', 'equity', 'to_balance', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans', 'avg_loan_repayment_rate', 'time_since_last_loan', 'time_since_last_loan_month', 'percentage_unrepaid_loans']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# 1. Split your data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Check for class imbalance and perform resampling if needed\n",
    "# Assuming '1' is the minority class\n",
    "X_resampled, y_resampled = resample(X_train[y_train == 1], y_train[y_train == 1], n_samples=len(X_train[y_train == 0]), random_state=42)\n",
    "X_train_balanced = np.concatenate([X_train, X_resampled])\n",
    "y_train_balanced = np.concatenate([y_train, y_resampled])\n",
    "\n",
    "# 3. Handle missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_balanced_imputed = imputer.fit_transform(X_train_balanced)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "test_x_imputed = imputer.transform(test_x)\n",
    "\n",
    "# 4. Train a Random Forest Classifier with hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_search.fit(X_train_balanced_imputed, y_train_balanced)\n",
    "\n",
    "# 5. Evaluate the model on the test set\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred_test = best_rf_model.predict(X_test_imputed)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Accuracy on Test Data:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Classification Report on Test Data:\\n\", classification_report(y_test, y_pred_test))\n",
    "print(\"F1 Score on Test Data:\", f1_score(y_test, y_pred_test))\n",
    "\n",
    "# 6. Check feature importances\n",
    "feature_importances = best_rf_model.feature_importances_\n",
    "# Plot or print feature importances as needed\n",
    "\n",
    "# 7. Cross-validation for a more robust estimate of performance\n",
    "cv_scores = cross_val_score(best_rf_model, X_train_balanced_imputed, y_train_balanced, cv=5, scoring='f1')\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "print(\"Mean Cross-Validation Score:\", np.mean(cv_scores))\n",
    "\n",
    "# 8. Optional: Polynomial Features\n",
    "poly_model = make_pipeline(PolynomialFeatures(degree=2), RandomForestClassifier(random_state=42))\n",
    "poly_model.fit(X_train_balanced_imputed, y_train_balanced)\n",
    "y_pred_poly_test = poly_model.predict(test_x_imputed)\n",
    "\n",
    "print(\"Accuracy on Test Data (with Polynomial Features):\", accuracy_score(test_y, y_pred_poly_test))\n",
    "print(\"Classification Report on Test Data (with Polynomial Features):\\n\", classification_report(test_y, y_pred_poly_test))\n",
    "print(\"F1 Score on Test Data (with Polynomial Features):\", f1_score(test_y, y_pred_poly_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Model: Without Polynomial Features (Training Data) ====================\n",
      "Accuracy: 0.9994593133279265\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     45877\n",
      "           1       0.99      1.00      0.99      2210\n",
      "\n",
      "    accuracy                           1.00     48087\n",
      "   macro avg       1.00      1.00      1.00     48087\n",
      "weighted avg       1.00      1.00      1.00     48087\n",
      "\n",
      "F1 Score (Training Data): 0.9941282746160794\n",
      "\n",
      "==================== Model: Without Polynomial Features (Test Data) ====================\n",
      "Accuracy: 0.9971180708719306\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     33737\n",
      "           1       0.97      0.66      0.78       268\n",
      "\n",
      "    accuracy                           1.00     34005\n",
      "   macro avg       0.98      0.83      0.89     34005\n",
      "weighted avg       1.00      1.00      1.00     34005\n",
      "\n",
      "F1 Score (Test Data): 0.7822222222222223\n",
      "\n",
      "Confusion Matrix (Test Data):\n",
      "[[33731     6]\n",
      " [   92   176]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JenniferEbereChinabu\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a dataset named 'training_dataset'\n",
    "# Replace 'target_variable' with the actual target variable in your dataset\n",
    "numerical_features = ['is_deleted', 'gender', 'farm_size', 'is_blacklist', 'phone_invalid',\n",
    "'phone_number_status', 'coordinate_status', 'id_status', 'project_id',\n",
    "'hectare', 'total_loan_value', 'repayment_value', 'amount_repaid', 'insurance', 'crg', 'interest', 'admin_fee', 'equity',\n",
    "'to_balance', 'is_repaid', 'loan_approved', 'loan_approval_completed', 'loan_rejected', 'loan_reverted',\n",
    "'marital_status_Divorced', 'marital_status_Married', 'marital_status_Single', 'marital_status_Widow',\n",
    "'marital_status_Widower', 'transaction_type_Broker Payment', 'transaction_type_Com For Equity', 'transaction_type_Com To Input',\n",
    "'transaction_type_Loan Repayment', 'transaction_type_Storage', 'transaction_type_Storage To Trade', 'transaction_type_Trade',\n",
    "'payment_option_Cash Advance', 'payment_option_Trade Execution', 'debt_to_farm_size_ratio', 'total_loan_value_total', 'total_loans',\n",
    "'avg_loan_repayment_rate', 'time_since_last_loan', 'percentage_unrepaid_loans', 'time_since_last_loan_month']\n",
    "target_variable = 'fully_repaid_within_maturity'\n",
    "\n",
    "# Select features and target variable\n",
    "X = training_dataset[numerical_features]\n",
    "y = training_dataset[target_variable]\n",
    "\n",
    "test_x = test_dataset[numerical_features]\n",
    "test_y = test_dataset[target_variable]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "model_no_poly = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler(), BaggingClassifier(random_state=42))\n",
    "model_with_poly = make_pipeline(SimpleImputer(strategy='mean'), PolynomialFeatures(degree=2), StandardScaler(), BaggingClassifier(random_state=42))\n",
    "\n",
    "# Define hyperparameter grid for tuning\n",
    "param_dist = {\n",
    "    'baggingclassifier__n_estimators': [50, 100, 200],\n",
    "    'baggingclassifier__max_samples': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "# Define RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(model_with_poly, param_dist, n_iter=10, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# Train and evaluate models without and with polynomial features\n",
    "models = {'Without Polynomial Features': model_no_poly, 'With Polynomial Features': random_search}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the training data\n",
    "    y_pred_train = model.predict(X_test)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred_test = model.predict(test_x)\n",
    "\n",
    "    # Model evaluation for training dataset\n",
    "    print(\"=\"*20, f\"Model: {model_name} (Training Data)\", \"=\"*20)\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred_train)}')\n",
    "    print('Classification Report:\\n', classification_report(y_test, y_pred_train))\n",
    "    print(f'F1 Score (Training Data): {f1_score(y_test, y_pred_train)}\\n')\n",
    "\n",
    "    # Model evaluation for test dataset\n",
    "    print(\"=\"*20, f\"Model: {model_name} (Test Data)\", \"=\"*20)\n",
    "    print(f'Accuracy: {accuracy_score(test_y, y_pred_test)}')\n",
    "    print('Classification Report:\\n', classification_report(test_y, y_pred_test))\n",
    "    print(f'F1 Score (Test Data): {f1_score(test_y, y_pred_test)}\\n')\n",
    "\n",
    "     # Confusion Matrix for test dataset\n",
    "    cm = confusion_matrix(test_y, y_pred_test)\n",
    "    print('Confusion Matrix (Test Data):')\n",
    "    print(cm)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
